{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChargingEnvironment(gym.Env):\n",
    "    def __init__(self, charging_capacity=100, charging_rate=10):\n",
    "        super(ChargingEnvironment, self).__init__()\n",
    "        \n",
    "        #Environment parameters\n",
    "        self.charging_capacity = charging_capacity # Total battery capacity\n",
    "        self.charging_rate = charging_rate #charging rate in unites per hour\n",
    "        \n",
    "        #Observation spcae\n",
    "        low = np.array([0.0, 0, 0], dtype = np.float32)\n",
    "        high = np.array([1.0, 24, np.inf], dtype = np.float32)\n",
    "        self.observation_space = spaces.Box(low = low, high = high, dtype = np.float32)\n",
    "        \n",
    "        #Action_space (charging decision)\n",
    "        self.action_space = spaces.Discrete(2)  # 0: Do not charge, 1: Charge\n",
    "        \n",
    "        #Internal state variables\n",
    "        self.current_charge = self.charging_capacity\n",
    "        self.hours_til_next_shift = 24\n",
    "        self.current_hour = 0\n",
    "        \n",
    "    def step(self, action):\n",
    "        #update the environment based on the agents action\n",
    "        if action == 1: #Charge\n",
    "            self.current_charge += self.charging_rate\n",
    "            self.current_charge = min(self.current_charge, self.charging_capacity)\n",
    "            \n",
    "        #Simulate time progression\n",
    "        self.current_hour += 1\n",
    "        self.hours_til_next_shift -= 1\n",
    "        \n",
    "        #Calculate reward(negative of charging cost)\n",
    "        electricity_price = self.get_electricity_price(self.current_hour)\n",
    "        reward = -action * self.charging_rate * electricity_price\n",
    "        \n",
    "        #Check for termination condition\n",
    "        done = self.hours_til_next_shift = 0 or self.current_charge >= self.charging_capacity\n",
    "        \n",
    "        observation = self.get_observation()\n",
    "        \n",
    "        return observation, reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        #Reset the environment to its initial state\n",
    "        self.current_charge = self.charging_capacity\n",
    "        self.hours_til_next_shift = 24\n",
    "        self.current_hour = 0\n",
    "        \n",
    "    def get_observation(self):\n",
    "        return np.array([\n",
    "            self.current_charge / self.charging_capacity, #normalized charging level\n",
    "            self.hours_til_next_shift,\n",
    "            self.get_electricity_price(self.current_hour)\n",
    "            \n",
    "        ])\n",
    "        \n",
    "    def get_electricity_price(self, hour):\n",
    "    # This is a simple example where the price is higher during the day and lower at night\n",
    "        if 8 <= hour <= 18:\n",
    "            return 0.15  # Daytime electricity price\n",
    "        else:\n",
    "            return 0.08  # Nighttime electricity price\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo import ParallelEnv\n",
    "\n",
    "class CustomEnvironment(ParallelEnv):\n",
    "    metadata = {\n",
    "        \"name\": \"custom_environment_v0\",\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self, seed=None, options = None):\n",
    "        pass\n",
    "    \n",
    "    def step(self, actions):\n",
    "        pass\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "    \n",
    "    def observation_space(self, agent):\n",
    "        return self.observation_spaces[agent]\n",
    "    \n",
    "    def action_space(self, agent):\n",
    "        return self.action_spaces[agent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "import time\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evcharge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
